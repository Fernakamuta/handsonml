{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mission: Code my own SoftMax Regression without Scikit-Learn Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Info:\n",
      "m: 120\n",
      "n: 5 (including theta0)\n",
      "k: 3\n",
      "X_train shape:  (120, 5)\n",
      "Y_train shape:  (120, 3)\n",
      "X_val shape:  (30, 5)\n",
      "Y_val shape:  (30, 3)\n",
      "Theta shape:  (5, 3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Preparing X\n",
    "X_scaled = StandardScaler().fit_transform(X)\n",
    "X_scaled = np.c_[np.ones((len(X_scaled), 1)) ,X_scaled] # 1 on left\n",
    "\n",
    "y_encoded = OneHotEncoder().fit_transform(y.reshape(-1, 1)).toarray()\n",
    "\n",
    "# Splitting Train / Val\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_scaled, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Training Vars\n",
    "m, n = X_train.shape\n",
    "k = len(np.unique(y))\n",
    "\n",
    "# Initial Theta (shape must be nxk)\n",
    "np.random.seed(50)\n",
    "theta_initial = np.random.rand(n, k)\n",
    "\n",
    "print('Training Info:')\n",
    "print('m:', m)\n",
    "print('n:', n, '(including theta0)')\n",
    "print('k:', k)\n",
    "print('X_train shape: ', X_train.shape)\n",
    "print('Y_train shape: ', y_train.shape)\n",
    "print('X_val shape: ', X_val.shape)\n",
    "print('Y_val shape: ', y_val.shape)\n",
    "print('Theta shape: ', theta.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00031746, -0.0099579 ,  0.00964044],\n",
       "       [ 0.00405785, -0.00299366, -0.0010642 ],\n",
       "       [-0.00387146, -0.00123082,  0.00510228],\n",
       "       [ 0.00752029,  0.00297834, -0.01049863],\n",
       "       [ 0.00690526,  0.00387651, -0.01078177]])"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calc_accuracy_score(y, y_train):\n",
    "    y_label = np.argmax(y, axis=1)\n",
    "\n",
    "    ok_preds = y_label == y_train\n",
    "    return sum(ok_preds) / len(ok_preds)\n",
    "\n",
    "\n",
    "def calc_accuracy(X, y, theta):\n",
    "    \"\"\"Calculates Model Accuracy\"\"\"\n",
    "    y_targets = np.argmax(y, axis=1)\n",
    "\n",
    "    y_preds = X.dot(theta)\n",
    "    y_targets_preds = np.argmax(y_preds, axis=1)\n",
    "    \n",
    "    ok_preds = y_targets == y_targets_preds\n",
    "    return round(sum(ok_preds) / len(ok_preds), 2)\n",
    "\n",
    "def predict(X, theta):\n",
    "    \"\"\"Predicts some X\"\"\"\n",
    "    pred = X.dot(theta)\n",
    "    return np.argmax(pred, axis=1)\n",
    "\n",
    "def softmax_function(pred_i_k, preds_i_k):\n",
    "    \"\"\"SoftMax Function\n",
    "        pred_i_k: the score of the observation i for class k\n",
    "        preds_i_k: the scores of the observatio i for all classes\n",
    "    \"\"\"\n",
    "    return np.exp(pred_i_k) / (np.exp(preds_i_k).sum())\n",
    "\n",
    "def cost_function(X, y, theta):\n",
    "    \"\"\"Returns the cost function\"\"\"\n",
    "    sum_acc = 0\n",
    "    \n",
    "    m = len(X)\n",
    "    _, K = theta.shape\n",
    "    \n",
    "    for i in range(0, m):\n",
    "        preds_i = X[i].dot(theta) # Returns an array k dimensional, with the probability of each\n",
    "        for k in range(0, K):\n",
    "            yk = y[i][k]\n",
    "            pk = softmax_function(preds_i[k], preds_i)\n",
    "            \n",
    "            sum_acc = sum_acc + yk * np.log(pk)\n",
    "    return -1 / m * sum_acc\n",
    "\n",
    "def calc_gradients(X, y, theta):\n",
    "    \"\"\"Return the gradients.\"\"\"\n",
    "    m = len(X)\n",
    "    _, K = theta.shape\n",
    "    \n",
    "    grads = np.zeros_like(theta)\n",
    "    \n",
    "    for i in range(0, m):\n",
    "        preds_i = X[i].dot(theta)\n",
    "        for k in range(0, K):\n",
    "            yk = y[i][k]\n",
    "            pk = softmax_function(preds_i[k], preds_i)\n",
    "            \n",
    "            grads[:, k] = grads[:, k] + (pk - yk) * X[i]\n",
    "    \n",
    "    return 1 / m * grads\n",
    "            \n",
    "\n",
    "calc_gradients(X_train, y_train, theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_softmax_early_stopping(X_train, y_train, X_val, y_val,theta, epoch=0, train_errors=[], val_errors=[], eta=0.1, max_iters=1000):\n",
    "#     print(f'***** Epoch: {epoch} *****')\n",
    "#     print('Cost function:', cost_function(X_train, y_train, theta), '\\n')\n",
    "\n",
    "    train_accuracy = calc_accuracy(X_train, y_train, theta)\n",
    "    val_accuracy = calc_accuracy(X_val, y_val, theta)\n",
    "    \n",
    "    train_errors.append(1 - train_accuracy)\n",
    "    val_errors.append(1 - val_accuracy)\n",
    "    \n",
    "    gradients = calc_gradients(X_train, y_train, theta)\n",
    "    theta = theta - eta * gradients\n",
    "    \n",
    "    if epoch > max_iters:\n",
    "        return theta, train_errors, val_errors\n",
    "\n",
    "    return train_softmax_early_stopping(X_train, y_train, X_val, y_val, theta, epoch + 1, train_errors, val_errors)\n",
    "\n",
    "\n",
    "theta, train_errors, val_errors = train_softmax_early_stopping(X_train, y_train, X_val, y_val, theta_initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.97\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(calc_accuracy(X_train, y_train, theta))\n",
    "print(calc_accuracy(X_val, y_val, theta))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.1 64-bit ('venv': virtualenv)",
   "language": "python",
   "name": "python37164bitvenvvirtualenva155b21064864e30bb3f17cab6903829"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
